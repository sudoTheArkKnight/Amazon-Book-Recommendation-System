{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T08:21:41.593692Z",
     "start_time": "2024-08-26T08:21:41.586180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ],
   "id": "33e74c0ee08a2c6e",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T08:21:41.728621Z",
     "start_time": "2024-08-26T08:21:41.720900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ],
   "id": "5fedd8f8ef548c8c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abhis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abhis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T08:21:41.835953Z",
     "start_time": "2024-08-26T08:21:41.746676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"A:/00BaseProjects/Amazon Book Recommendation System/data/Books_df.csv\")\n",
    "\n",
    "# Drop unnecessary column and convert object columns to string\n",
    "data.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "data = data.astype({col: 'string' for col in data.select_dtypes(['object']).columns})\n",
    "\n"
   ],
   "id": "7ac4d2f3ef1260d8",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T08:21:41.938988Z",
     "start_time": "2024-08-26T08:21:41.930656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a function to tokenize and preprocess text\n",
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return []\n",
    "    else:\n",
    "        tokens = word_tokenize(text.lower())  # Convert to lowercase\n",
    "        tokens = [t for t in tokens if t.isalpha()]  # Remove non-alphabetic tokens\n",
    "        tokens = [t for t in tokens if t not in stopwords.words('english')]  # Remove stopwords\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(t) for t in tokens]  # Lemmatize tokens\n",
    "        return tokens\n",
    "\n"
   ],
   "id": "60a037b911bb31eb",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T08:22:02.063198Z",
     "start_time": "2024-08-26T08:21:42.036694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply preprocessing to relevant columns\n",
    "data['text_tokenized'] = data['Title'].apply(preprocess_text)\n",
    "data['Author_tokenized'] = data['Author'].apply(preprocess_text)\n",
    "data['Main_Genre_tokenized'] = data['Main Genre'].apply(preprocess_text)\n",
    "data['Sub_Genre_tokenized'] = data['Sub Genre'].apply(preprocess_text)\n"
   ],
   "id": "f7a05d669f3e6faa",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T08:22:04.300591Z",
     "start_time": "2024-08-26T08:22:02.130671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TF-IDF vectorizer object\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit the vectorizer to the tokenized text data and transform it into a matrix\n",
    "tfidf_matrix = vectorizer.fit_transform([' '.join(tokens) for tokens in data['text_tokenized']])\n",
    "\n",
    "# Convert the matrix to a dense array\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "\n",
    "# Create a new dataframe with the TF-IDF features\n",
    "tfidf_df = pd.DataFrame(tfidf_array, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Merge the TF-IDF dataframe with the original data\n",
    "data = pd.concat([data, tfidf_df], axis=1)\n",
    "\n",
    "# Repeat the process for author, main genre, and sub genre columns\n",
    "author_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "author_tfidf_matrix = author_vectorizer.fit_transform([' '.join(tokens) for tokens in data['Author_tokenized']])\n",
    "author_tfidf_array = author_tfidf_matrix.toarray()\n",
    "author_tfidf_df = pd.DataFrame(author_tfidf_array, columns=author_vectorizer.get_feature_names_out())\n",
    "data = pd.concat([data, author_tfidf_df], axis=1)\n",
    "\n",
    "main_genre_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "main_genre_tfidf_matrix = main_genre_vectorizer.fit_transform(\n",
    "    [' '.join(tokens) for tokens in data['Main_Genre_tokenized']])\n",
    "main_genre_tfidf_array = main_genre_tfidf_matrix.toarray()\n",
    "main_genre_tfidf_df = pd.DataFrame(main_genre_tfidf_array, columns=main_genre_vectorizer.get_feature_names_out())\n",
    "data = pd.concat([data, main_genre_tfidf_df], axis=1)\n",
    "\n",
    "sub_genre_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "sub_genre_tfidf_matrix = sub_genre_vectorizer.fit_transform(\n",
    "    [' '.join(tokens) for tokens in data['Sub_Genre_tokenized']])\n",
    "sub_genre_tfidf_array = sub_genre_tfidf_matrix.toarray()\n",
    "sub_genre_tfidf_df = pd.DataFrame(sub_genre_tfidf_array, columns=sub_genre_vectorizer.get_feature_names_out())\n",
    "data = pd.concat([data, sub_genre_tfidf_df], axis=1)\n",
    "\n"
   ],
   "id": "b6ede85f9af93aa4",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T08:22:04.406238Z",
     "start_time": "2024-08-26T08:22:04.397299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to find 5 closest titles\n",
    "def find_closest_titles(book_title, data, tfidf_matrix):\n",
    "    # Preprocess the input book title\n",
    "    book_title_tokens = preprocess_text(book_title)\n",
    "\n",
    "    # Convert the book title to a vector using the same vectorizer\n",
    "    title_vector = vectorizer.transform([' '.join(book_title_tokens)])\n",
    "\n",
    "    # Calculate the cosine similarity between the title vector and the entire TF-IDF matrix\n",
    "    cosine_similarities = cosine_similarity(title_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    # Get the indices of the top 5 most similar books\n",
    "    similar_indices = cosine_similarities.argsort()[-6:-1][::-1]\n",
    "\n",
    "    # Get the titles of the most similar books\n",
    "    similar_titles = data.iloc[similar_indices]['Title'].tolist()\n",
    "\n",
    "    return similar_titles"
   ],
   "id": "67b38e8cdbd0b9f5",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T08:22:04.510115Z",
     "start_time": "2024-08-26T08:22:04.492621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "book_title = \"Black Holes (L) : The Reith Lectures [Paperback] Hawking, Stephen\"\n",
    "closest_titles = find_closest_titles(book_title, data, tfidf_matrix)\n",
    "print(\"The 5 closest titles to '{}':\".format(book_title))\n",
    "for i, title in enumerate(closest_titles, 1):\n",
    "    print(f\"{i}. {title}\")"
   ],
   "id": "4a14e3ed3e4d4977",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 closest titles to 'Black Holes (L) : The Reith Lectures [Paperback] Hawking, Stephen':\n",
      "1. Black Holes (L) : The Reith Lectures [Paperback] Hawking, Stephen\n",
      "2. Holes\n",
      "3. Holes\n",
      "4. On the Shoulders of Giants: The Great Works of Physics and Astronomy [Paperback] Hawking, Stephen\n",
      "5. A Brief History of Time: From Big Bang to Black Holes\n"
     ]
    }
   ],
   "execution_count": 92
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
